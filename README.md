# Assistant Vocal Temps RÃ©el

Assistant vocal conversationnel en temps rÃ©el utilisant les technologies de pointe pour la reconnaissance vocale, la gÃ©nÃ©ration de langage et la synthÃ¨se vocale.

## FonctionnalitÃ©s

- Conversation vocale en temps rÃ©el avec reconnaissance et synthÃ¨se instantanÃ©es
- Support multilingue (franÃ§ais, anglais, et autres langues supportÃ©es par Whisper et EdgeTTS)
- Interruptions naturelles - vous pouvez interrompre l'assistant en parlant
- Turn detection intelligent - dÃ©tection automatique des fins de phrases
- Streaming LLM - rÃ©ponses fluides gÃ©nÃ©rÃ©es en temps rÃ©el
- Interface terminal simple - pas besoin de navigateur
- Architecture multi-thread optimisÃ©e pour une latence minimale

## Technologies

| Composant | Technologie | Description |
| --------- | ----------- | ----------- |
| **STT** | Whisper small | Reconnaissance vocale multilingue rapide et prÃ©cise |
| **LLM** | Ollama ministral-3 | GÃ©nÃ©ration de rÃ©ponses intelligentes en streaming |
| **TTS** | EdgeTTS | SynthÃ¨se vocale multilingue via Azure (voix neuronales) |

## ğŸ“‹ PrÃ©requis

### DÃ©pendances systÃ¨me

1. **Python 3.10+** avec `uv` installÃ©
2. **Ollama** avec le modÃ¨le `ministral-3` ou `llama3.2:3b`
3. **PortAudio** pour l'accÃ¨s au microphone
4. **FFmpeg** pour le traitement audio
5. **MPV** pour la lecture audio (utilisÃ© par EdgeTTS)

### Installation macOS

```bash
# Installer Homebrew si nÃ©cessaire
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Installer les dÃ©pendances systÃ¨me
brew install portaudio ffmpeg mpv

# Installer Ollama
brew install ollama

# DÃ©marrer Ollama et tÃ©lÃ©charger le modÃ¨le
ollama serve &
ollama pull ministral-3
# ou
ollama pull llama3.2:3b
```

### Installation Linux (Ubuntu/Debian)

```bash
# DÃ©pendances systÃ¨me
sudo apt-get update
sudo apt-get install portaudio19-dev ffmpeg mpv

# Installer Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# TÃ©lÃ©charger le modÃ¨le
ollama pull ministral-3
```

## ğŸš€ Installation

```bash
# Cloner ou naviguer vers le projet
cd ~/Code/realtime-voice-assistant

# Les dÃ©pendances Python sont dÃ©jÃ  configurÃ©es dans pyproject.toml
# uv les installera automatiquement lors du premier lancement
```

## â–¶ï¸ Utilisation

### DÃ©marrage simple

```bash
# DÃ©marrer l'assistant
uv run main.py
```

### Au premier lancement

Le systÃ¨me va :

1. VÃ©rifier qu'Ollama et le modÃ¨le LLM sont disponibles
2. Initialiser les composants (STT, LLM, TTS)
3. TÃ©lÃ©charger les modÃ¨les Whisper si nÃ©cessaire (~40 MB pour tiny, ~140 MB pour small)
4. DÃ©marrer l'Ã©coute du microphone

### Utilisation

1. **Parlez clairement** dans votre microphone
2. **Attendez** la transcription et la rÃ©ponse
3. **Interrompez** l'assistant en recommenÃ§ant Ã  parler
4. **Quittez** avec `Ctrl+C`

## Configuration

### Changer la voix EdgeTTS

Ã‰ditez [tts_module.py](tts_module.py#L11) pour modifier la voix :

```python
EDGE_TTS_VOICE = "en-US-AvaMultilingualNeural"  # Voix multilingue par dÃ©faut
```

Voix populaires:

- **Multilingue**: `en-US-AvaMultilingualNeural` (supporte franÃ§ais, anglais, espagnol, etc.)
- **FranÃ§ais**: `fr-FR-DeniseNeural`, `fr-FR-HenriNeural`
- **Anglais**: `en-US-AriaNeural`, `en-GB-SoniaNeural`

Liste complÃ¨te : [Microsoft TTS Voices](https://learn.microsoft.com/azure/ai-services/speech-service/language-support)

### Modifier le prompt systÃ¨me

Ã‰ditez [system_prompt.txt](system_prompt.txt) pour changer la personnalitÃ© de l'assistant.

### Ajuster le modÃ¨le Whisper

Ã‰ditez [stt_module.py](stt_module.py#L28) :

```python
"model": "small",  # Options: "tiny", "base", "small", "medium"
```

**Note**: Les modÃ¨les plus grands sont plus prÃ©cis mais plus lents.

### Changer le modÃ¨le LLM

Ã‰ditez [main.py](main.py#L27) :

```python
LLM_MODEL = "ministral-3"  # Options: "ministral-3", "llama3.2:3b", etc.
```

## Architecture

### Vue d'ensemble

Le systÃ¨me est conÃ§u autour d'une architecture pipeline en temps rÃ©el avec trois composants principaux:

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Microphone  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Audio 48kHz
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STT (Whisper)      â”‚
â”‚  - ModÃ¨le: small    â”‚
â”‚  - Multilingue      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Texte transcrit
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM (Ollama)        â”‚
â”‚  - ministral-3      â”‚
â”‚  - Streaming        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ RÃ©ponse (chunks)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TTS (EdgeTTS)      â”‚
â”‚  - Voice: Multi     â”‚
â”‚  - MP3/Opus         â”‚
â”‚  - Lecture via MPV  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Audio
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Haut-parleursâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture Multi-Thread

Le systÃ¨me utilise **deux threads workers** indÃ©pendants pour minimiser la latence:

#### Thread 1: LLM Worker

- Ã‰coute les nouvelles entrÃ©es utilisateur via `new_input_event`
- GÃ©nÃ¨re les rÃ©ponses en streaming via l'API Ollama
- Place chaque chunk de texte dans `text_queue`
- GÃ¨re l'interruption via `abort_event`

#### Thread 2: TTS Worker

- Consomme les chunks de texte de `text_queue`
- SynthÃ©tise l'audio via EdgeTTS
- **Joue l'audio directement via MPV** (format MP3/Opus)
- Supporte l'interruption pour les rÃ©ponses rÃ©actives

**Note importante**: EdgeTTS gÃ©nÃ¨re de l'audio au format MP3/Opus qui est jouÃ© directement par MPV. Il n'y a pas de conversion en PCM ni de thread Audio Player sÃ©parÃ©, ce qui simplifie l'architecture et amÃ©liore la performance.

### Flux de donnÃ©es

```text
USER INPUT â†’ STT â†’ [text_queue] â†’ LLM â†’ [text_queue] â†’ TTS â†’ MPV â†’ SPEAKERS
                     â†‘                                       â†‘
                     â””â”€â”€â”€â”€â”€â”€ abort_event (interruption) â”€â”€â”€â”€â”˜
```

### Gestion des interruptions

Le systÃ¨me supporte deux types d'interruptions:

1. **Interruption par la voix**: DÃ©tectÃ©e par `stt_module` via `on_recording_start_callback`
2. **DÃ©tection de silence**: GÃ©rÃ©e par `silence_active_callback` qui surveille l'Ã©tat du silence

Quand une interruption est dÃ©tectÃ©e:

- `abort_event` est activÃ©
- Les deux threads arrÃªtent leur traitement en cours
- La queue `text_queue` est vidÃ©e
- Le stream audio MPV est arrÃªtÃ©
- Une nouvelle gÃ©nÃ©ration peut dÃ©marrer

### Turn Detection

Le module `turn_detection.py` calcule dynamiquement le temps d'attente optimal avant de finaliser une transcription, basÃ© sur:

- La longueur du texte transcrit
- La prÃ©sence de ponctuation finale
- La latence estimÃ©e du pipeline (LLM + TTS)

Ã‰tats du turn detection:

- **Cold**: Aucune activitÃ© vocale
- **Potential End**: Silence dÃ©tectÃ© aprÃ¨s ponctuation
- **Hot**: PrÃªt Ã  finaliser la transcription
- **Final**: Transcription finalisÃ©e et envoyÃ©e au LLM

### Composants principaux

- **[main.py](main.py)** - Point d'entrÃ©e et gestion du cycle de vie
- **[conversation_manager.py](conversation_manager.py)** - Orchestration des 2 threads workers
- **[stt_module.py](stt_module.py)** - Reconnaissance vocale avec RealtimeSTT
- **[tts_module.py](tts_module.py)** - SynthÃ¨se vocale avec EdgeTTS
- **[llm_module.py](llm_module.py)** - Interface avec Ollama
- **[turn_detection.py](turn_detection.py)** - DÃ©tection intelligente des tours de parole
- **[text_similarity.py](text_similarity.py)** - Comparaison de textes pour dÃ©duplication

## ğŸ› DÃ©pannage

### "Ollama connection refused"

```bash
# VÃ©rifier qu'Ollama tourne
ollama serve

# Dans un autre terminal
ollama list  # Doit afficher ministral-3 ou llama3.2:3b
```

### "Microphone not found"

- **macOS**: VÃ©rifiez les permissions micro dans PrÃ©fÃ©rences SystÃ¨me â†’ ConfidentialitÃ©
- **Linux**: VÃ©rifiez que votre utilisateur est dans le groupe `audio`

### "EdgeTTS voice not found"

VÃ©rifiez que la voix est correctement spÃ©cifiÃ©e dans [tts_module.py](tts_module.py#L11). Les voix EdgeTTS nÃ©cessitent une connexion Internet.

### "MPV not found"

EdgeTTS nÃ©cessite MPV pour jouer l'audio:

```bash
# macOS
brew install mpv

# Linux
sudo apt-get install mpv
```

### Audio robotique ou incomprÃ©hensible

Si l'audio EdgeTTS sonne mal, vÃ©rifiez que:

1. MPV est bien installÃ© (`which mpv`)
2. Vous avez une connexion Internet active
3. La voix spÃ©cifiÃ©e existe (voir la liste Microsoft)

## Performance

| MÃ©trique | Valeur typique |
| -------- | -------------- |
| Latence STT | ~0.5-1s |
| Latence LLM (TTFT) | ~0.5-1s |
| Latence TTS | ~0.2-0.4s |
| **Latence totale** | **~1.5-2.5s** |

Mesures effectuÃ©es sur MacBook M1/M2 avec ministral-3 et EdgeTTS.

## Structure du projet

```text
realtime-voice-assistant/
â”œâ”€â”€ README.md                # Ce fichier (documentation)
â”œâ”€â”€ main.py                  # Point d'entrÃ©e de l'application
â”œâ”€â”€ conversation_manager.py  # Orchestrateur des 2 threads workers
â”œâ”€â”€ stt_module.py            # Module STT (Whisper + RealtimeSTT)
â”œâ”€â”€ tts_module.py            # Module TTS (EdgeTTS)
â”œâ”€â”€ llm_module.py            # Module LLM (interface Ollama)
â”œâ”€â”€ turn_detection.py        # DÃ©tection intelligente des tours de parole
â”œâ”€â”€ text_similarity.py       # Comparaison et dÃ©duplication de textes
â”œâ”€â”€ logsetup.py              # Configuration du systÃ¨me de logging
â”œâ”€â”€ system_prompt.txt        # Prompt systÃ¨me de l'assistant
â”œâ”€â”€ pyproject.toml           # Configuration uv + dÃ©pendances Python
â””â”€â”€ .venv/                   # Environnement virtuel Python
```

## DÃ©veloppement

### Lancer en mode debug

Modifiez le niveau de log dans [main.py](main.py#L39) :

```python
setup_logging(logging.DEBUG)  # Au lieu de logging.INFO
```

### Architecture des callbacks

Le systÃ¨me utilise des callbacks pour la communication entre modules:

- `full_transcription_callback`: STT â†’ ConversationManager (texte finalisÃ©)
- `on_recording_start_callback`: STT â†’ ConversationManager (interruption dÃ©tectÃ©e)
- `silence_active_callback`: STT â†’ ConversationManager (Ã©tat du silence)
- `on_first_audio_chunk_synthesize`: TTS â†’ ConversationManager (premier chunk audio)

### Tests des composants

```bash
# Test du module LLM
uv run python llm_module.py

# Test du module TTS
uv run python -c "from tts_module import AudioProcessor; tts = AudioProcessor(); print('TTS OK')"
```

## AmÃ©liorations futures

- Commandes vocales (stop, recommence, etc.)
- Historique persistant des conversations
- Choix de voix EdgeTTS via arguments CLI
- Support multilingue avec changement de langue en temps rÃ©el
- MÃ©triques de latence et performance en temps rÃ©el
- Mode push-to-talk optionnel
- Interface web optionnelle pour monitoring

## Licence

Ce projet est basÃ© sur le projet [RealtimeVoiceChat](https://github.com/KoljaB/RealtimeVoiceChat) et utilise les bibliothÃ¨ques open-source suivantes:

- RealtimeSTT (MIT)
- RealtimeTTS (MIT)
- Transformers (Apache 2.0)
- Ollama (MIT)
- edge-tts (GPL-3.0)

## Remerciements

- [Whisper](https://github.com/openai/whisper) par OpenAI - reconnaissance vocale de haute qualitÃ©
- [Ollama](https://ollama.ai) - infÃ©rence LLM locale optimisÃ©e
- [EdgeTTS](https://github.com/rany2/edge-tts) - synthÃ¨se vocale via Microsoft Azure
- [RealtimeSTT](https://github.com/KoljaB/RealtimeSTT) et [RealtimeTTS](https://github.com/KoljaB/RealtimeTTS) par KoljaB - frameworks temps rÃ©el

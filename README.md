# ğŸ™ï¸ Assistant Vocal Temps RÃ©el (FranÃ§ais)

Assistant vocal conversationnel en temps rÃ©el utilisant les technologies de pointe pour la reconnaissance vocale, la gÃ©nÃ©ration de langage et la synthÃ¨se vocale.

## ğŸŒŸ FonctionnalitÃ©s

- **Conversation vocale en temps rÃ©el** avec reconnaissance et synthÃ¨se instantanÃ©es
- **Support complet du franÃ§ais** (transcription et synthÃ¨se)
- **Interruptions naturelles** - vous pouvez interrompre l'assistant en parlant
- **Turn detection intelligent** - dÃ©tection automatique des fins de phrases
- **Streaming LLM** - rÃ©ponses fluides gÃ©nÃ©rÃ©es en temps rÃ©el
- **Interface terminal simple** - pas besoin de navigateur

## ğŸ› ï¸ Technologies

| Composant | Technologie | Description |
|-----------|------------|-------------|
| **STT** | Whisper tiny | Reconnaissance vocale rapide et prÃ©cise |
| **LLM** | Ollama llama3.2:3b | GÃ©nÃ©ration de rÃ©ponses intelligentes |
| **TTS** | Kokoro (voix franÃ§aise) | SynthÃ¨se vocale naturelle |

## ğŸ“‹ PrÃ©requis

### DÃ©pendances systÃ¨me

1. **Python 3.10+** avec `uv` installÃ©
2. **Ollama** avec le modÃ¨le `llama3.2:3b`
3. **PortAudio** pour l'accÃ¨s au microphone
4. **FFmpeg** pour le traitement audio

### Installation macOS

```bash
# Installer Homebrew si nÃ©cessaire
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Installer les dÃ©pendances systÃ¨me
brew install portaudio ffmpeg

# Installer Ollama
brew install ollama

# DÃ©marrer Ollama et tÃ©lÃ©charger le modÃ¨le
ollama serve &
ollama pull llama3.2:3b
```

### Installation Linux (Ubuntu/Debian)

```bash
# DÃ©pendances systÃ¨me
sudo apt-get update
sudo apt-get install portaudio19-dev ffmpeg

# Installer Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# TÃ©lÃ©charger le modÃ¨le
ollama pull llama3.2:3b
```

## ğŸš€ Installation

```bash
# Cloner ou naviguer vers le projet
cd ~/Code/realtime-voice-assistant

# Les dÃ©pendances Python sont dÃ©jÃ  configurÃ©es dans pyproject.toml
# uv les installera automatiquement lors du premier lancement
```

## â–¶ï¸ Utilisation

### DÃ©marrage simple

```bash
# DÃ©marrer l'assistant
uv run main.py
```

### Au premier lancement

Le systÃ¨me va :
1. VÃ©rifier qu'Ollama et llama3.2:3b sont disponibles
2. Initialiser les composants (STT, LLM, TTS)
3. TÃ©lÃ©charger les modÃ¨les Whisper si nÃ©cessaire (~40 MB pour tiny)
4. DÃ©marrer l'Ã©coute du microphone

### Utilisation

1. **Parlez clairement** dans votre microphone
2. **Attendez** la transcription et la rÃ©ponse
3. **Interrompez** l'assistant en recommenÃ§ant Ã  parler
4. **Quittez** avec `Ctrl+C`

## âš™ï¸ Configuration

### Changer la voix franÃ§aise

Ã‰ditez [tts_module.py](tts_module.py:123) :

```python
self.engine = KokoroEngine(
    voice="af_sky",  # Options: "af_sky", "af_bella", "af"
    ...
)
```

### Modifier le prompt systÃ¨me

Ã‰ditez [system_prompt.txt](system_prompt.txt) pour changer la personnalitÃ© de l'assistant.

### Ajuster le modÃ¨le Whisper

Ã‰ditez [stt_module.py](stt_module.py:28) :

```python
"model": "tiny",  # Options: "tiny", "base", "small", "medium"
```

**Note**: Les modÃ¨les plus grands sont plus prÃ©cis mais plus lents.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Microphone  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Audio 48kHz
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STT (Whisper)      â”‚
â”‚  - ModÃ¨le: tiny     â”‚
â”‚  - Langue: fr       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Texte transcrit
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM (Ollama)        â”‚
â”‚  - llama3.2:3b      â”‚
â”‚  - Streaming        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ RÃ©ponse (chunks)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TTS (Kokoro)       â”‚
â”‚  - Voix: af_sky     â”‚
â”‚  - FranÃ§ais         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Audio
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Haut-parleursâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants principaux

- **[main.py](main.py)** - Point d'entrÃ©e et gestion du cycle de vie
- **[conversation_manager.py](conversation_manager.py)** - Orchestration des 3 composants
- **[stt_module.py](stt_module.py)** - Reconnaissance vocale avec RealtimeSTT
- **[tts_module.py](tts_module.py)** - SynthÃ¨se vocale avec RealtimeTTS
- **[llm_module.py](llm_module.py)** - Interface avec Ollama
- **[turn_detection.py](turn_detection.py)** - DÃ©tection intelligente des tours de parole

## ğŸ› DÃ©pannage

### "Ollama connection refused"

```bash
# VÃ©rifier qu'Ollama tourne
ollama serve

# Dans un autre terminal
ollama list  # Doit afficher llama3.2:3b
```

### "Microphone not found"

- **macOS**: VÃ©rifiez les permissions micro dans PrÃ©fÃ©rences SystÃ¨me â†’ ConfidentialitÃ©
- **Linux**: VÃ©rifiez que votre utilisateur est dans le groupe `audio`

### "Kokoro voice af_sky not found"

Essayez une autre voix franÃ§aise :
- `af_bella`
- `af` (voix gÃ©nÃ©rique)

### Audio hachÃ© ou saccadÃ©

Augmentez la taille des chunks dans [tts_module.py](tts_module.py:102) :

```python
self.current_stream_chunk_size = 30  # Augmenter de 8 Ã  30
```

## ğŸ“Š Performance

| MÃ©trique | Valeur typique |
|----------|----------------|
| Latence STT | ~0.5-1s |
| Latence LLM (TTFT) | ~1-2s |
| Latence TTS | ~0.3-0.5s |
| **Latence totale** | **~2-3s** |

*Mesures sur MacBook M1/M2 avec llama3.2:3b*

## ğŸ“ Structure du projet

```
realtime-voice-assistant/
â”œâ”€â”€ PLAN.md                  # Plan d'implÃ©mentation dÃ©taillÃ©
â”œâ”€â”€ README.md                # Ce fichier
â”œâ”€â”€ main.py                  # Point d'entrÃ©e
â”œâ”€â”€ conversation_manager.py  # Orchestrateur principal
â”œâ”€â”€ stt_module.py           # Module STT (Whisper)
â”œâ”€â”€ tts_module.py           # Module TTS (Kokoro)
â”œâ”€â”€ llm_module.py           # Module LLM (Ollama)
â”œâ”€â”€ turn_detection.py       # DÃ©tection des tours de parole
â”œâ”€â”€ text_context.py         # Analyse de contexte textuel
â”œâ”€â”€ text_similarity.py      # SimilaritÃ© de textes
â”œâ”€â”€ colors.py               # Utilitaires couleurs terminal
â”œâ”€â”€ logsetup.py             # Configuration du logging
â”œâ”€â”€ system_prompt.txt       # Prompt systÃ¨me de l'assistant
â”œâ”€â”€ pyproject.toml          # Configuration uv + dÃ©pendances
â””â”€â”€ .venv/                  # Environnement virtuel Python
```

## ğŸ”§ DÃ©veloppement

### Lancer en mode debug

```bash
# Modifier le niveau de log dans main.py
setup_logging(logging.DEBUG)
```

### Tester un composant isolÃ©ment

```python
# Test STT
uv run python -c "from stt_module import TranscriptionProcessor; ..."

# Test TTS
uv run python -c "from tts_module import AudioProcessor; ..."
```

## ğŸ¯ AmÃ©liorations futures

- [ ] Commandes vocales ("stop", "recommence")
- [ ] Historique persistant des conversations
- [ ] Choix de voix via arguments CLI
- [ ] Indicateur visuel d'activitÃ© (animation terminal)
- [ ] Support multilingue (en/fr switchable)
- [ ] MÃ©triques de latence en temps rÃ©el
- [ ] Mode "Ã©coute continue" vs "push-to-talk"

## ğŸ“œ Licence

Ce projet est basÃ© sur le projet [RealtimeVoiceChat](https://github.com/KoljaB/RealtimeVoiceChat) et utilise les bibliothÃ¨ques open-source suivantes:
- RealtimeSTT (MIT)
- RealtimeTTS (MIT)
- Transformers (Apache 2.0)
- Ollama (MIT)

## ğŸ™ Remerciements

- [Whisper](https://github.com/openai/whisper) par OpenAI
- [Ollama](https://ollama.ai) pour l'infÃ©rence LLM locale
- [Kokoro-82M](https://huggingface.co/hexgrad/Kokoro-82M) pour la synthÃ¨se vocale franÃ§aise
- [RealtimeSTT](https://github.com/KoljaB/RealtimeSTT) et [RealtimeTTS](https://github.com/KoljaB/RealtimeTTS) par KoljaB

# Assistant Vocal Temps RÃ©el

Assistant vocal conversationnel en temps rÃ©el utilisant les technologies de pointe pour la reconnaissance vocale, la gÃ©nÃ©ration de langage et la synthÃ¨se vocale.

## FonctionnalitÃ©s

- Conversation vocale en temps rÃ©el avec reconnaissance et synthÃ¨se instantanÃ©es
- Support complet du franÃ§ais et de l'anglais (transcription et synthÃ¨se)
- Interruptions naturelles - vous pouvez interrompre l'assistant en parlant
- Turn detection intelligent - dÃ©tection automatique des fins de phrases
- Streaming LLM - rÃ©ponses fluides gÃ©nÃ©rÃ©es en temps rÃ©el
- Interface terminal simple - pas besoin de navigateur
- Architecture multi-thread optimisÃ©e pour une latence minimale

## Technologies

| Composant | Technologie | Description |
| --------- | ----------- | ----------- |
| **STT** | Whisper small | Reconnaissance vocale rapide et prÃ©cise |
| **LLM** | Ollama ministral-3 | GÃ©nÃ©ration de rÃ©ponses intelligentes |
| **TTS** | EdgeTTS | SynthÃ¨se vocale multilingue via Azure |

## ğŸ“‹ PrÃ©requis

### DÃ©pendances systÃ¨me

1. **Python 3.10+** avec `uv` installÃ©
2. **Ollama** avec le modÃ¨le `llama3.2:3b`
3. **PortAudio** pour l'accÃ¨s au microphone
4. **FFmpeg** pour le traitement audio

### Installation macOS

```bash
# Installer Homebrew si nÃ©cessaire
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Installer les dÃ©pendances systÃ¨me
brew install portaudio ffmpeg

# Installer Ollama
brew install ollama

# DÃ©marrer Ollama et tÃ©lÃ©charger le modÃ¨le
ollama serve &
ollama pull llama3.2:3b
```

### Installation Linux (Ubuntu/Debian)

```bash
# DÃ©pendances systÃ¨me
sudo apt-get update
sudo apt-get install portaudio19-dev ffmpeg

# Installer Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# TÃ©lÃ©charger le modÃ¨le
ollama pull llama3.2:3b
```

## ğŸš€ Installation

```bash
# Cloner ou naviguer vers le projet
cd ~/Code/realtime-voice-assistant

# Les dÃ©pendances Python sont dÃ©jÃ  configurÃ©es dans pyproject.toml
# uv les installera automatiquement lors du premier lancement
```

## â–¶ï¸ Utilisation

### DÃ©marrage simple

```bash
# DÃ©marrer l'assistant
uv run main.py
```

### Au premier lancement

Le systÃ¨me va :
1. VÃ©rifier qu'Ollama et llama3.2:3b sont disponibles
2. Initialiser les composants (STT, LLM, TTS)
3. TÃ©lÃ©charger les modÃ¨les Whisper si nÃ©cessaire (~40 MB pour tiny)
4. DÃ©marrer l'Ã©coute du microphone

### Utilisation

1. **Parlez clairement** dans votre microphone
2. **Attendez** la transcription et la rÃ©ponse
3. **Interrompez** l'assistant en recommenÃ§ant Ã  parler
4. **Quittez** avec `Ctrl+C`

## Configuration

### Changer le moteur TTS

Le systÃ¨me supporte deux moteurs TTS. Ã‰ditez [main.py](main.py:28) :

```python
TTS_MODEL = "edge_tts"  # Options: "edge_tts", "kokoro"
```

### Changer la voix EdgeTTS

Ã‰ditez [tts_module.py](tts_module.py:33) pour modifier les voix par langue :

```python
EDGE_TTS_VOICES = {
    "fr": "fr-FR-DeniseNeural",  # Voix franÃ§aise
    "en": "en-US-AvaMultilingualNeural",  # Voix anglaise
}
```

Liste des voix disponibles : [Microsoft TTS Voices](https://learn.microsoft.com/azure/ai-services/speech-service/language-support)

### Modifier le prompt systÃ¨me

Ã‰ditez [system_prompt.txt](system_prompt.txt) pour changer la personnalitÃ© de l'assistant.

### Ajuster le modÃ¨le Whisper

Ã‰ditez [stt_module.py](stt_module.py:28) :

```python
"model": "tiny",  # Options: "tiny", "base", "small", "medium"
```

**Note**: Les modÃ¨les plus grands sont plus prÃ©cis mais plus lents.

## Architecture

### Vue d'ensemble

Le systÃ¨me est conÃ§u autour d'une architecture pipeline en temps rÃ©el avec trois composants principaux:

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Microphone  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Audio 48kHz
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STT (Whisper)      â”‚
â”‚  - ModÃ¨le: small    â”‚
â”‚  - Langue: fr/en    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Texte transcrit
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM (Ollama)        â”‚
â”‚  - ministral-3      â”‚
â”‚  - Streaming        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ RÃ©ponse (chunks)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TTS (EdgeTTS)      â”‚
â”‚  - Voice: Multi     â”‚
â”‚  - Streaming        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Audio
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Haut-parleursâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture Multi-Thread

Le systÃ¨me utilise trois threads workers indÃ©pendants pour minimiser la latence:

#### Thread 1: LLM Worker

- Ã‰coute les nouvelles entrÃ©es utilisateur via `new_input_event`
- GÃ©nÃ¨re les rÃ©ponses en streaming via l'API Ollama
- Place chaque chunk de texte dans `text_queue`
- GÃ¨re l'interruption via `abort_event`

#### Thread 2: TTS Worker

- Consomme les chunks de texte de `text_queue`
- SynthÃ©tise l'audio via EdgeTTS ou Kokoro
- Place les chunks audio dans `audio_queue`
- Supporte l'interruption pour les rÃ©ponses rÃ©actives

#### Thread 3: Audio Player Worker

- Lit les chunks audio de `audio_queue`
- Joue l'audio via PyAudio (format: PCM 16-bit, 24kHz mono)
- Bufferise 5 chunks minimum avant de commencer
- ArrÃªt immÃ©diat sur interruption utilisateur

### Flux de donnÃ©es

```text
USER INPUT â†’ STT â†’ [text_queue] â†’ LLM â†’ [text_queue] â†’ TTS â†’ [audio_queue] â†’ Audio Player â†’ SPEAKERS
                     â†‘                                              â†‘
                     â””â”€â”€â”€â”€â”€â”€â”€â”€ abort_event (interruption) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Gestion des interruptions

Le systÃ¨me supporte deux types d'interruptions:

1. **Interruption par la voix**: DÃ©tectÃ©e par `stt_module` via `on_recording_start_callback`
2. **DÃ©tection de silence**: GÃ©rÃ©e par `silence_active_callback` qui surveille l'Ã©tat du silence

Quand une interruption est dÃ©tectÃ©e:

- `abort_event` est activÃ©
- Les trois threads arrÃªtent leur traitement en cours
- Les queues `text_queue` et `audio_queue` sont vidÃ©es
- Une nouvelle gÃ©nÃ©ration peut dÃ©marrer

### Turn Detection

Le module `turn_detection.py` calcule dynamiquement le temps d'attente optimal avant de finaliser une transcription, basÃ© sur:

- La longueur du texte transcrit
- La prÃ©sence de ponctuation finale
- La latence estimÃ©e du pipeline (LLM + TTS)

Ã‰tats du turn detection:

- **Cold**: Aucune activitÃ© vocale
- **Potential End**: Silence dÃ©tectÃ© aprÃ¨s ponctuation
- **Hot**: PrÃªt Ã  finaliser la transcription
- **Final**: Transcription finalisÃ©e et envoyÃ©e au LLM

### Composants principaux

- **[main.py](main.py)** - Point d'entrÃ©e et gestion du cycle de vie
- **[conversation_manager.py](conversation_manager.py)** - Orchestration des 3 threads workers
- **[stt_module.py](stt_module.py)** - Reconnaissance vocale avec RealtimeSTT
- **[tts_module.py](tts_module.py)** - SynthÃ¨se vocale avec EdgeTTS/Kokoro
- **[llm_module.py](llm_module.py)** - Interface avec Ollama
- **[turn_detection.py](turn_detection.py)** - DÃ©tection intelligente des tours de parole
- **[text_similarity.py](text_similarity.py)** - Comparaison de textes pour dÃ©duplication

## ğŸ› DÃ©pannage

### "Ollama connection refused"

```bash
# VÃ©rifier qu'Ollama tourne
ollama serve

# Dans un autre terminal
ollama list  # Doit afficher llama3.2:3b
```

### "Microphone not found"

- **macOS**: VÃ©rifiez les permissions micro dans PrÃ©fÃ©rences SystÃ¨me â†’ ConfidentialitÃ©
- **Linux**: VÃ©rifiez que votre utilisateur est dans le groupe `audio`

### "EdgeTTS voice not found"

VÃ©rifiez que la voix est correctement spÃ©cifiÃ©e dans [tts_module.py](tts_module.py:33). Les voix EdgeTTS nÃ©cessitent une connexion Internet.

### Audio hachÃ© ou saccadÃ© avec Kokoro

Si vous utilisez le moteur Kokoro, augmentez la taille des buffers dans la configuration du moteur.

## Performance

| MÃ©trique | Valeur typique |
| -------- | -------------- |
| Latence STT | ~0.5-1s |
| Latence LLM (TTFT) | ~0.5-1s |
| Latence TTS | ~0.2-0.4s |
| **Latence totale** | **~1.5-2.5s** |

Mesures effectuÃ©es sur MacBook M1/M2 avec ministral-3 et EdgeTTS.

## Structure du projet

```text
realtime-voice-assistant/
â”œâ”€â”€ PLAN.md                  # Plan d'implÃ©mentation dÃ©taillÃ©
â”œâ”€â”€ README.md                # Ce fichier (documentation)
â”œâ”€â”€ main.py                  # Point d'entrÃ©e de l'application
â”œâ”€â”€ conversation_manager.py  # Orchestrateur des 3 threads workers
â”œâ”€â”€ stt_module.py            # Module STT (Whisper + RealtimeSTT)
â”œâ”€â”€ tts_module.py            # Module TTS (EdgeTTS / Kokoro)
â”œâ”€â”€ llm_module.py            # Module LLM (interface Ollama)
â”œâ”€â”€ turn_detection.py        # DÃ©tection intelligente des tours de parole
â”œâ”€â”€ text_similarity.py       # Comparaison et dÃ©duplication de textes
â”œâ”€â”€ logsetup.py              # Configuration du systÃ¨me de logging
â”œâ”€â”€ system_prompt.txt        # Prompt systÃ¨me de l'assistant
â”œâ”€â”€ pyproject.toml           # Configuration uv + dÃ©pendances Python
â””â”€â”€ .venv/                   # Environnement virtuel Python
```

## DÃ©veloppement

### Lancer en mode debug

Modifiez le niveau de log dans [main.py](main.py:39) :

```python
setup_logging(logging.DEBUG)  # Au lieu de logging.INFO
```

### Architecture des callbacks

Le systÃ¨me utilise des callbacks pour la communication entre modules:

- `full_transcription_callback`: STT â†’ ConversationManager (texte finalisÃ©)
- `on_recording_start_callback`: STT â†’ ConversationManager (interruption dÃ©tectÃ©e)
- `silence_active_callback`: STT â†’ ConversationManager (Ã©tat du silence)
- `on_first_audio_chunk_synthesize`: TTS â†’ ConversationManager (premier chunk audio)

### Tests des composants

```bash
# Test du module LLM
uv run python llm_module.py

# Test du module TTS (nÃ©cessite EdgeTTS ou Kokoro)
uv run python -c "from tts_module import AudioProcessor; tts = AudioProcessor('edge_tts', 'fr'); print('TTS OK')"
```

## AmÃ©liorations futures

- Commandes vocales (stop, recommence, etc.)
- Historique persistant des conversations
- Choix de voix et moteur TTS via arguments CLI
- Support multilingue avec changement de langue en temps rÃ©el
- MÃ©triques de latence et performance en temps rÃ©el
- Mode push-to-talk optionnel
- Interface web optionnelle pour monitoring

## Licence

Ce projet est basÃ© sur le projet [RealtimeVoiceChat](https://github.com/KoljaB/RealtimeVoiceChat) et utilise les bibliothÃ¨ques open-source suivantes:

- RealtimeSTT (MIT)
- RealtimeTTS (MIT)
- Transformers (Apache 2.0)
- Ollama (MIT)
- edge-tts (GPL-3.0)

## Remerciements

- [Whisper](https://github.com/openai/whisper) par OpenAI - reconnaissance vocale de haute qualitÃ©
- [Ollama](https://ollama.ai) - infÃ©rence LLM locale optimisÃ©e
- [EdgeTTS](https://github.com/rany2/edge-tts) - synthÃ¨se vocale via Microsoft Azure
- [Kokoro-82M](https://huggingface.co/hexgrad/Kokoro-82M) - synthÃ¨se vocale multilingue alternative
- [RealtimeSTT](https://github.com/KoljaB/RealtimeSTT) et [RealtimeTTS](https://github.com/KoljaB/RealtimeTTS) par KoljaB - frameworks temps rÃ©el

# main_bis.py - Version Terminal (sans web/WebSocket)
import logging
import signal
import threading
import time
import asyncio

from logsetup import setup_logging

setup_logging(logging.INFO)
logger = logging.getLogger(__name__)

logger.info("üñ•Ô∏èüëã D√©marrage de l'assistant vocal en mode terminal")

import pyaudio
from colors import Colors
from speech_pipeline_manager import SpeechPipelineManager
from audio_in import AudioInputProcessor

# --------------------------------------------------------------------
# Configuration
# --------------------------------------------------------------------
TTS_START_ENGINE = "edgeTTS"
LLM_START_PROVIDER = "ollama"
LLM_START_MODEL = "ministral-3"
LANGUAGE = "fr"

# Configuration PyAudio
SAMPLE_RATE = 48000  # AudioInputProcessor attend 48kHz (resample vers 16kHz)
CHUNK_SIZE = 1024
CHANNELS = 1
FORMAT = pyaudio.paInt16


# --------------------------------------------------------------------
# Callbacks pour le terminal
# --------------------------------------------------------------------
class TerminalCallbacks:
    """G√®re les callbacks de transcription pour le mode terminal."""

    def __init__(self, pipeline: SpeechPipelineManager, audio_processor: AudioInputProcessor):
        self.pipeline = pipeline
        self.audio_processor = audio_processor
        self.final_transcription = ""
        self.partial_transcription = ""
        self.user_finished_turn = False
        self.tts_playing = False
        self.interruption_time = 0.0

    def on_partial(self, txt: str):
        """Callback pour les transcriptions partielles."""
        self.partial_transcription = txt
        print(f"\r{Colors.CYAN}[Vous]: {txt}{Colors.RESET}".ljust(80), end="", flush=True)

    def on_potential_sentence(self, txt: str):
        """Callback quand une phrase potentielle est d√©tect√©e."""
        logger.debug(f"üéôÔ∏è Phrase potentielle: '{txt}'")
        self.pipeline.prepare_generation(txt)

    def on_potential_final(self, txt: str):
        """Callback quand on approche de la fin de la transcription."""
        logger.info(f"{Colors.MAGENTA}üéôÔ∏è HOT: {txt}{Colors.RESET}")

    def on_before_final(self, audio: bytes, txt: str):
        """Callback juste avant la transcription finale."""
        print()  # Nouvelle ligne apr√®s le partial
        logger.info(f"{Colors.GREEN}üéôÔ∏è Fin du tour utilisateur{Colors.RESET}")
        self.user_finished_turn = True

        # Bloquer le micro pendant le TTS
        if not self.audio_processor.interrupted:
            logger.info(f"{Colors.CYAN}üéôÔ∏è ‚è∏Ô∏è Microphone interrompu (fin de tour){Colors.RESET}")
            self.audio_processor.interrupted = True
            self.interruption_time = time.time()

        # Permettre la synth√®se TTS
        if self.pipeline.is_valid_gen():
            self.pipeline.running_generation.tts_quick_allowed_event.set()

        # Ajouter √† l'historique
        user_text = self.final_transcription if self.final_transcription else self.partial_transcription
        if user_text:
            logger.info(f"üéôÔ∏è Ajout √† l'historique: '{user_text}'")
            self.pipeline.history.append({"role": "user", "content": user_text})

    def on_final(self, txt: str):
        """Callback pour la transcription finale."""
        self.final_transcription = txt
        print(f"{Colors.GREEN}[Vous]: {txt}{Colors.RESET}")
        self.partial_transcription = ""

    def on_recording_start(self):
        """Callback quand l'enregistrement commence."""
        logger.info(f"{Colors.ORANGE}üéôÔ∏è Enregistrement d√©marr√©{Colors.RESET}")

        # Si le TTS jouait, on interrompt
        if self.tts_playing:
            logger.info(f"{Colors.RED}üõë Interruption du TTS par l'utilisateur{Colors.RESET}")
            self.pipeline.abort_generation(reason="User interrupted")
            self.tts_playing = False

    def on_silence_active(self, is_silent: bool):
        """Callback quand l'√©tat de silence change."""
        pass

    def on_partial_assistant_text(self, txt: str):
        """Callback pour le texte partiel de l'assistant."""
        print(f"\r{Colors.YELLOW}[Assistant]: {txt}{Colors.RESET}".ljust(80), end="", flush=True)

    def send_final_assistant_answer(self):
        """Envoie la r√©ponse finale de l'assistant."""
        if self.pipeline.is_valid_gen():
            answer = self.pipeline.running_generation.quick_answer + self.pipeline.running_generation.final_answer
            if answer:
                print(f"\n{Colors.GREEN}[Assistant]: {answer}{Colors.RESET}")
                self.pipeline.history.append({"role": "assistant", "content": answer})


# --------------------------------------------------------------------
# Capture microphone avec PyAudio
# --------------------------------------------------------------------
class MicrophoneCapture:
    """Capture le microphone et met les chunks dans une queue."""

    def __init__(self, audio_queue: asyncio.Queue, loop: asyncio.AbstractEventLoop):
        self.audio_queue = audio_queue
        self.loop = loop
        self.running = False
        self.thread = None
        self.pyaudio = None
        self.stream = None

    def start(self):
        """D√©marre la capture du microphone."""
        self.running = True
        self.thread = threading.Thread(target=self._capture_loop, daemon=True)
        self.thread.start()
        logger.info("üé§ Capture microphone d√©marr√©e")

    def stop(self):
        """Arr√™te la capture du microphone."""
        self.running = False
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        if self.pyaudio:
            self.pyaudio.terminate()
        logger.info("üé§ Capture microphone arr√™t√©e")

    def _capture_loop(self):
        """Boucle de capture dans un thread s√©par√©."""
        try:
            self.pyaudio = pyaudio.PyAudio()
            self.stream = self.pyaudio.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=SAMPLE_RATE,
                input=True,
                frames_per_buffer=CHUNK_SIZE,
            )

            while self.running:
                try:
                    data = self.stream.read(CHUNK_SIZE, exception_on_overflow=False)
                    # Cr√©er le dictionnaire de m√©tadonn√©es comme attendu par AudioInputProcessor
                    audio_data = {"pcm": data}
                    # Mettre dans la queue de fa√ßon thread-safe
                    self.loop.call_soon_threadsafe(lambda d=audio_data: self.audio_queue.put_nowait(d))
                except Exception as e:
                    if self.running:
                        logger.error(f"üé§ Erreur capture: {e}")
                    break

        except Exception as e:
            logger.error(f"üé§ Erreur initialisation PyAudio: {e}")
        finally:
            if self.stream:
                self.stream.stop_stream()
                self.stream.close()
            if self.pyaudio:
                self.pyaudio.terminate()


# --------------------------------------------------------------------
# Fonction principale async
# --------------------------------------------------------------------
async def main_async(pipeline: SpeechPipelineManager):
    """Point d'entr√©e principal asynchrone."""
    # Initialiser AudioInputProcessor ICI (n√©cessite event loop actif)
    audio_processor = AudioInputProcessor(language=LANGUAGE)

    # Cr√©er les callbacks
    callbacks = TerminalCallbacks(pipeline, audio_processor)

    # Configurer les callbacks sur l'AudioInputProcessor
    audio_processor.realtime_callback = callbacks.on_partial
    audio_processor.transcriber.potential_sentence_end = callbacks.on_potential_sentence
    audio_processor.transcriber.potential_full_transcription_callback = callbacks.on_potential_final
    audio_processor.transcriber.full_transcription_callback = callbacks.on_final
    audio_processor.transcriber.before_final_sentence = callbacks.on_before_final
    audio_processor.recording_start_callback = callbacks.on_recording_start
    audio_processor.silence_active_callback = callbacks.on_silence_active

    # Callback pour le texte partiel de l'assistant
    pipeline.on_partial_assistant_text = callbacks.on_partial_assistant_text

    # Queue pour les chunks audio
    audio_queue = asyncio.Queue()

    # Capture microphone
    loop = asyncio.get_event_loop()
    mic_capture = MicrophoneCapture(audio_queue, loop)

    # Gestion de l'arr√™t propre
    shutdown_event = asyncio.Event()

    def signal_handler(sig, frame):
        logger.info("\nüõë Arr√™t demand√© (Ctrl+C)")
        loop.call_soon_threadsafe(shutdown_event.set)

    signal.signal(signal.SIGINT, signal_handler)

    logger.info(f"{Colors.GREEN}‚úÖ Pr√™t ! Parlez dans le microphone. Ctrl+C pour quitter.{Colors.RESET}")
    print("-" * 60)

    # D√©marrer la capture micro
    mic_capture.start()

    # Lancer le traitement des chunks audio
    audio_task = asyncio.create_task(audio_processor.process_chunk_queue(audio_queue))

    try:
        while not shutdown_event.is_set():
            await asyncio.sleep(0.1)

            # Reset du flag interrupted apr√®s un d√©lai
            if (
                audio_processor.interrupted
                and callbacks.interruption_time
                and time.time() - callbacks.interruption_time > 2.0
            ):
                logger.info(f"{Colors.CYAN}üéôÔ∏è ‚ñ∂Ô∏è Microphone r√©activ√©{Colors.RESET}")
                audio_processor.interrupted = False
                callbacks.interruption_time = 0

            # V√©rifier si le TTS a commenc√©
            if (
                pipeline.running_generation
                and pipeline.running_generation.quick_answer_first_chunk_ready
                and not callbacks.tts_playing
            ):
                callbacks.tts_playing = True
                logger.info(f"{Colors.BLUE}üîä TTS d√©marr√©{Colors.RESET}")

            # V√©rifier si une g√©n√©ration est termin√©e
            if (
                pipeline.running_generation
                and pipeline.running_generation.audio_quick_finished
                and not pipeline.running_generation.abortion_started
            ):
                if (
                    pipeline.running_generation.audio_final_finished
                    or not pipeline.running_generation.quick_answer_provided
                ):
                    callbacks.send_final_assistant_answer()
                    pipeline.running_generation = None
                    callbacks.tts_playing = False

                    # R√©activer le micro apr√®s la fin du TTS
                    if audio_processor.interrupted:
                        logger.info(f"{Colors.CYAN}üéôÔ∏è ‚ñ∂Ô∏è Microphone r√©activ√© (fin TTS){Colors.RESET}")
                        audio_processor.interrupted = False
                        callbacks.interruption_time = 0

    except asyncio.CancelledError:
        pass
    finally:
        logger.info("üßπ Nettoyage...")
        mic_capture.stop()
        audio_task.cancel()
        try:
            await audio_task
        except asyncio.CancelledError:
            pass
        audio_processor.shutdown()


def main():
    """Point d'entr√©e principal."""
    logger.info("üöÄ Initialisation des composants...")

    # Initialiser le pipeline de synth√®se vocale AVANT la boucle async
    # (EdgeEngine utilise asyncio.run() en interne)
    pipeline = SpeechPipelineManager(
        tts_engine=TTS_START_ENGINE,
        llm_provider=LLM_START_PROVIDER,
        llm_model=LLM_START_MODEL,
    )

    try:
        asyncio.run(main_async(pipeline))
    finally:
        # Cleanup
        pipeline.shutdown()
        logger.info("üëã Au revoir !")


if __name__ == "__main__":
    main()
